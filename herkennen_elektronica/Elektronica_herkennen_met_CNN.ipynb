{"cells":[{"metadata":{},"cell_type":"markdown","source":"The Idea is to apply CNN to Cats&Dogs Image Classification dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport os\nfrom tensorflow.keras.preprocessing import image\nfrom zipfile import ZipFile ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# importing libraries for Deep Learning\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"# test_dir=\"../input/electronic-components/images_test/\"\ntrain_dir=\"../input/electronic-components/images/\"\n\ntrain_dir_LEDS = train_dir + '/LED'\ntrain_dir_transistor = train_dir + '/transistor'\n# test_dir_cats = test_dir + '/LED'\n# test_dir_dogs = test_dir + '/transistor'","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('number of LEDs training images - ',len(os.listdir(train_dir_LEDS)))\nprint('number of transistors training images - ',len(os.listdir(train_dir_transistor)))\n# print('number of cats testing images - ',len(os.listdir(test_dir_cats)))\n# print('number of dogs testing images - ',len(os.listdir(test_dir_dogs)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Now we need to convert the RGB images into array of numbers. The requirement can be satisfied by ImageDataGenerator() https://keras.io/preprocessing/image/"},{"metadata":{"trusted":true},"cell_type":"code","source":"data_generator = ImageDataGenerator(rescale = 1.0/255.0, zoom_range = 0.2)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"batch_size = 32\ntraining_data = data_generator.flow_from_directory(directory = train_dir,\n                                                   target_size = (64, 64),\n                                                   batch_size = batch_size,\n                                                   class_mode = 'binary')\n# testing_data = data_generator.flow_from_directory(directory = test_dir,\n# target_size = (64, 64),\n#                                                   batch_size = batch_size,\n#                                                   class_mode = 'binary')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# preparing the layers in the Convolutional Deep Neural Network\nmodel = Sequential()\nmodel.add(Conv2D(filters = 32, kernel_size = (3, 3), activation = 'relu', input_shape = training_data.image_shape))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(rate = 0.3))\nmodel.add(Conv2D(filters = 64, kernel_size = (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(rate = 0.2))\nmodel.add(Conv2D(filters = 126, kernel_size = (3, 3), activation = 'relu'))\nmodel.add(MaxPooling2D(pool_size = (2, 2)))\nmodel.add(Dropout(rate = 0.15))\nmodel.add(Flatten())\nmodel.add(Dense(units = 32, activation = 'relu'))\nmodel.add(Dropout(rate = 0.15))\nmodel.add(Dense(units = 64, activation = 'relu'))\nmodel.add(Dropout(rate = 0.1))\nmodel.add(Dense(units = len(set(training_data.classes)), activation = 'softmax'))\nmodel.compile(optimizer = 'adam', loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model.summary()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"fitted_model = model.fit_generator(training_data,\n                        steps_per_epoch = 1000,\n                        epochs = 25)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# plotting accuracy and validation accuracy\naccuracy = fitted_model.history['acc']\nplt.plot(range(len(accuracy)), accuracy, 'bo', label = 'accuracy')\nplt.legend()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# testing the model\ndef testing_image(image_directory):\n    test_image = image.load_img(image_directory, target_size = (64, 64))\n    test_image = image.img_to_array(test_image)\n    test_image = np.expand_dims(test_image, axis = 0)\n    result = model.predict(x = test_image)\n    print(result)\n    if result[0][0]  == 1:\n        prediction = 'Dog'\n    else:\n        prediction = 'Cat'\n    return prediction","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(testing_image(test_dir + '/cats/cat.4003.jpg'))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":1}